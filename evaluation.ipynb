{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map full words to shorthand CVSS codes\n",
    "cvss_value_map = {\n",
    "    \"None\": \"N\",\n",
    "    \"Low\": \"L\",\n",
    "    \"Medium\": \"M\",\n",
    "    \"High\": \"H\",\n",
    "    \"Network\": \"N\",\n",
    "    \"Adjacent\": \"A\",\n",
    "    \"Local\": \"L\",\n",
    "    \"Physical\": \"P\",\n",
    "    \"Required\": \"R\",\n",
    "    \"Changed\": \"C\",\n",
    "    \"Unchanged\": \"U\"\n",
    "}\n",
    "\n",
    "# Define valid options per component\n",
    "cvss_options = {\n",
    "    \"AV\": [\"N\", \"A\", \"L\", \"P\"],\n",
    "    \"AC\": [\"L\", \"H\"],\n",
    "    \"PR\": [\"N\", \"L\", \"H\"],\n",
    "    \"UI\": [\"N\", \"R\"],\n",
    "    \"S\": [\"U\", \"C\"],\n",
    "    \"C\": [\"N\", \"L\", \"H\"],\n",
    "    \"I\": [\"N\", \"L\", \"H\"],\n",
    "    \"A\": [\"N\", \"L\", \"H\"]\n",
    "}\n",
    "\n",
    "def extract_cvss_value(component, text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"?\"\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    if '<think>' in text:\n",
    "        text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Try to match shorthand (e.g., AV:L)\n",
    "    match = re.search(rf\"{component}\\s*:\\s*([A-Z])\", text, flags=re.IGNORECASE)\n",
    "    if match and match.group(1) in cvss_options[component]:\n",
    "        return match.group(1)\n",
    "\n",
    "    # Try to match full name\n",
    "    for full, code in cvss_value_map.items():\n",
    "        if re.search(rf\"\\b{full}\\b\", text, flags=re.IGNORECASE):\n",
    "            if code in cvss_options[component]:\n",
    "                return code\n",
    "\n",
    "    # Try to find any valid short code mentioned\n",
    "    for code in cvss_options[component]:\n",
    "        if re.search(rf\"\\b{code}\\b\", text):\n",
    "            return code\n",
    "\n",
    "    return \"?\"\n",
    "\n",
    "# Apply to your dataframe\n",
    "def clean_cvss_responses(df):\n",
    "    components = {\n",
    "        \"AV\": \"AV_response\",\n",
    "        \"AC\": \"AC_response\",\n",
    "        \"PR\": \"PR_response\",\n",
    "        \"UI\": \"UI_response\",\n",
    "        \"S\": \"S_response\",\n",
    "        \"C\": \"C_response\",\n",
    "        \"I\": \"I_response\",\n",
    "        \"A\": \"A_response\"\n",
    "    }\n",
    "\n",
    "    for component, col in components.items():\n",
    "        new_col = component + \"_clean\"\n",
    "        df[new_col] = df[col].apply(lambda x: extract_cvss_value(component, x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = []\n",
    "csv_data = {}\n",
    "\n",
    "for root, dirs, files in os.walk('./results/llms'):\n",
    "    for file in sorted(files):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            csv_files.append(file)\n",
    "            csv_data[file] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_parquet('./dataset.parquet')\n",
    "df_gt.rename(columns={col: f\"{col}_true\" for col in [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]}, inplace=True)\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_data = {key: value for key, value in csv_data.items() if \"components\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_results = []\n",
    "\n",
    "for key, df in components_data.items():\n",
    "    # Clean CVSS responses\n",
    "    cleaned_df = clean_cvss_responses(df)\n",
    "\n",
    "    # Drop the original response columns\n",
    "    response_columns = [\n",
    "        \"AV_response\", \"AC_response\", \"PR_response\", \n",
    "        \"UI_response\", \"S_response\", \"C_response\", \n",
    "        \"I_response\", \"A_response\"\n",
    "    ]\n",
    "    cleaned_df.drop(columns=response_columns, inplace=True)\n",
    "\n",
    "    # Update the dataframe in components_data\n",
    "    components_data[key] = cleaned_df\n",
    "\n",
    "    # Merge with ground truth\n",
    "    merged_df = cleaned_df.merge(df_gt[[\n",
    "        'cve_id', 'AV_true', 'AC_true', 'PR_true', \n",
    "        'UI_true', 'S_true', 'C_true', 'I_true', 'A_true'\n",
    "    ]], on='cve_id', suffixes=('_pred', '_true'))\n",
    "\n",
    "    # Components to evaluate\n",
    "    components = [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]\n",
    "    accuracy_row = {}\n",
    "\n",
    "    for comp in components:\n",
    "        y_true = merged_df[f\"{comp}_true\"]\n",
    "        y_pred = merged_df[f\"{comp}_clean\"]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracy_row[comp] = acc\n",
    "\n",
    "    # Add model name (strip suffix)\n",
    "    model_name = key.replace('_components.csv', '')\n",
    "    accuracy_row[\"model\"] = model_name\n",
    "\n",
    "    # Append result\n",
    "    components_results.append(accuracy_row)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(components_results)\n",
    "\n",
    "# Reorder columns so 'model' is first\n",
    "cols = ['model'] + [col for col in results_df.columns if col != 'model']\n",
    "results_df = results_df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('./results/components.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = {key: value for key, value in csv_data.items() if \"_vector.csv\" in key and 'cwe' not in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to parse CVSS vector\n",
    "def parse_vector_string(vector_text):\n",
    "    components = {}\n",
    "    matches = re.findall(r\"([A-Z]{1,2}):([A-Z])\", vector_text)\n",
    "    for comp, val in matches:\n",
    "        if comp in cvss_options and val in cvss_options[comp]:\n",
    "            components[comp] = val\n",
    "    return components\n",
    "\n",
    "# Extract from noisy text\n",
    "def extract_component_from_text(component, text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"?\"\n",
    "\n",
    "    # 1. Try from full CVSS vector\n",
    "    vector_parts = parse_vector_string(text)\n",
    "    if component in vector_parts:\n",
    "        return vector_parts[component]\n",
    "\n",
    "    # 2. Try matching \"AV: N\", \"AV - N\", etc.\n",
    "    match = re.search(rf\"{component}\\s*[:\\-]?\\s*([A-Z])\\b\", text)\n",
    "    if match and match.group(1) in cvss_options[component]:\n",
    "        return match.group(1)\n",
    "\n",
    "    # 3. Try full word (e.g., \"Network\" â†’ \"N\")\n",
    "    for full, code in cvss_value_map.items():\n",
    "        if code in cvss_options[component] and re.search(rf\"{full}\", text, re.IGNORECASE):\n",
    "            return code\n",
    "\n",
    "    # 4. Last resort: search for any valid code in text\n",
    "    for code in cvss_options[component]:\n",
    "        if re.search(rf\"\\b{code}\\b\", text):\n",
    "            return code\n",
    "\n",
    "    return \"?\"\n",
    "\n",
    "# Clean function to extract components from messy LLM vector\n",
    "def extract_components_from_llm_vector(df, vector_column=\"cvss_response\"):\n",
    "    component_list = [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]\n",
    "    for comp in component_list:\n",
    "        df[f\"{comp}_clean\"] = df[vector_column].apply(lambda x: extract_component_from_text(comp, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_results = []\n",
    "\n",
    "for key, df in vector_data.items():\n",
    "    # Clean CVSS responses\n",
    "    cleaned_df = df = extract_components_from_llm_vector(df, vector_column=\"response\")\n",
    "\n",
    "    # Merge with ground truth\n",
    "    merged_df = cleaned_df.merge(df_gt[[\n",
    "        'cve_id', 'AV_true', 'AC_true', 'PR_true', \n",
    "        'UI_true', 'S_true', 'C_true', 'I_true', 'A_true'\n",
    "    ]], on='cve_id', suffixes=('_pred', '_true'))\n",
    "\n",
    "    # Components to evaluate\n",
    "    components = [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]\n",
    "    accuracy_row = {}\n",
    "\n",
    "    for comp in components:\n",
    "        y_true = merged_df[f\"{comp}_true\"]\n",
    "        y_pred = merged_df[f\"{comp}_clean\"]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracy_row[comp] = acc\n",
    "\n",
    "    # Add model name (strip suffix)\n",
    "    model_name = key.replace('_vector.csv', '')\n",
    "    accuracy_row[\"model\"] = model_name\n",
    "\n",
    "    # Append result\n",
    "    vector_results.append(accuracy_row)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(vector_results)\n",
    "\n",
    "# Reorder columns so 'model' is first\n",
    "cols = ['model'] + [col for col in results_df.columns if col != 'model']\n",
    "results_df = results_df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('./results/vector.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_few_shot_data = {key: value for key, value in csv_data.items() if \"_vector_few_shot.csv\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_few_shot_results = []\n",
    "\n",
    "for key, df in vector_few_shot_data.items():\n",
    "    # Clean CVSS responses\n",
    "    cleaned_df = df = extract_components_from_llm_vector(df, vector_column=\"response\")\n",
    "\n",
    "    # Merge with ground truth\n",
    "    merged_df = cleaned_df.merge(df_gt[[\n",
    "        'cve_id', 'AV_true', 'AC_true', 'PR_true', \n",
    "        'UI_true', 'S_true', 'C_true', 'I_true', 'A_true'\n",
    "    ]], on='cve_id', suffixes=('_pred', '_true'))\n",
    "\n",
    "    # Components to evaluate\n",
    "    components = [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]\n",
    "    accuracy_row = {}\n",
    "\n",
    "    for comp in components:\n",
    "        y_true = merged_df[f\"{comp}_true\"]\n",
    "        y_pred = merged_df[f\"{comp}_clean\"]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracy_row[comp] = acc\n",
    "\n",
    "    # Add model name (strip suffix)\n",
    "    model_name = key.replace('_vector_few_shot.csv', '')\n",
    "    accuracy_row[\"model\"] = model_name\n",
    "\n",
    "    # Append result\n",
    "    vector_few_shot_results.append(accuracy_row)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(vector_few_shot_results)\n",
    "\n",
    "# Reorder columns so 'model' is first\n",
    "cols = ['model'] + [col for col in results_df.columns if col != 'model']\n",
    "results_df = results_df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('./results/vector_few_shot.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector CWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_vector_data = {key: value for key, value in csv_data.items() if \"_cwe_vector.csv\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_vector_results = []\n",
    "\n",
    "for key, df in cwe_vector_data.items():\n",
    "    # Clean CVSS responses\n",
    "    cleaned_df = df = extract_components_from_llm_vector(df, vector_column=\"response\")\n",
    "\n",
    "    # Merge with ground truth\n",
    "    merged_df = cleaned_df.merge(df_gt[[\n",
    "        'cve_id', 'AV_true', 'AC_true', 'PR_true', \n",
    "        'UI_true', 'S_true', 'C_true', 'I_true', 'A_true'\n",
    "    ]], on='cve_id', suffixes=('_pred', '_true'))\n",
    "\n",
    "    # Components to evaluate\n",
    "    components = [\"AV\", \"AC\", \"PR\", \"UI\", \"S\", \"C\", \"I\", \"A\"]\n",
    "    accuracy_row = {}\n",
    "\n",
    "    for comp in components:\n",
    "        y_true = merged_df[f\"{comp}_true\"]\n",
    "        y_pred = merged_df[f\"{comp}_clean\"]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracy_row[comp] = acc\n",
    "\n",
    "    # Add model name (strip suffix)\n",
    "    model_name = key.replace('_cwe_vector.csv', '')\n",
    "    accuracy_row[\"model\"] = model_name\n",
    "\n",
    "    # Append result\n",
    "    cwe_vector_results.append(accuracy_row)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(cwe_vector_results)\n",
    "\n",
    "# Reorder columns so 'model' is first\n",
    "cols = ['model'] + [col for col in results_df.columns if col != 'model']\n",
    "results_df = results_df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('./results/cwe_vector.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVSS Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_data = {key: value for key, value in csv_data.items() if \"_score.csv\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score_from_response(response):\n",
    "    if not isinstance(response, str):\n",
    "        if isinstance(response, float):\n",
    "            return response\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Remove content between <think> brackets\n",
    "    response = re.sub(r\"<think>.*?</think>\", \"\", response, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Find the last number in the format x.x\n",
    "    match = re.search(r\"(\\d+\\.\\d+)(?!.*\\d+\\.\\d+)\", response)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "\n",
    "    if len(response) == 3:\n",
    "        return response\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "score_results = []\n",
    "\n",
    "for key, df in score_data.items():\n",
    "    # Clean CVSS responses\n",
    "    df[\"score_clean\"] = df[\"response\"].apply(extract_score_from_response)\n",
    "    df = df.drop(columns=[\"response\"])\n",
    "\n",
    "    # Add CVSS score from df_gt\n",
    "    df = df.merge(df_gt[['cve_id', 'cvss']], on='cve_id', how='left', suffixes=('', '_true'))\n",
    "\n",
    "    # Calculate distance\n",
    "    mse = ((df[\"score_clean\"] - df[\"cvss\"]) ** 2).mean()\n",
    "    mae = (df[\"score_clean\"] - df[\"cvss\"]).abs().mean()\n",
    "    rmse = ((df[\"score_clean\"] - df[\"cvss\"]) ** 2).mean() ** 0.5\n",
    "\n",
    "    # Add model name (strip suffix)\n",
    "    model_name = key.replace('_score.csv', '')\n",
    "\n",
    "    # Append result\n",
    "    score_results.append({\"model\": model_name,\n",
    "                          \"mse\": mse,\n",
    "                          \"mae\": mae,\n",
    "                          \"rmse\": rmse})\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(score_results)\n",
    "\n",
    "# Reorder columns so 'model' is first\n",
    "cols = ['model'] + [col for col in results_df.columns if col != 'model']\n",
    "results_df = results_df[cols]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('./results/score.csv', index=False)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
